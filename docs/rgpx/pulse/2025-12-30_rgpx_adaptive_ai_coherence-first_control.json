{
  "slug": "2025-12-30_rgpx_adaptive_ai_coherence-first_control",
  "date": "2025-12-30",
  "source_path": "pulse/2025-12-30_rgpx_adaptive_ai_coherence-first_control.yml",
  "data": {
    "title": "Adaptive AI without forgetting: RGPx as a coherence-first control layer",
    "summary": "core_claim: \n  The brittle loop (world shifts → performance degrades → retrain → forget) is a symptom of blind plasticity.\n  RGPx fixes this by moving “adaptation” out of global weight-updates and into a coherence-governed control layer.\n  The ‘mystery’ is a control-theory gap: we lack observables for drift + acceptance gates for change.\n\ntransition_grammar: \n  Operationalize Δ → GC → CF: measure drift as deltas (Δ), schedule targeted interventions as choreographies (GC),\n  and protect stable identity/constraints as contextual filters (CF), so learning becomes selective rather than destructive.\n\npractical_application:\n  - \"Δ sensing: continuously measure drift signatures (distribution shift, error-mode change, calibration overhead creep, IO/latency drift, confidence–reality divergence).\"\n  - \"GC control: intervene via routing, verification loops, retrieval/tools, and localized fine-tunes only in implicated subspaces—avoid global retrains by default.\"\n  - \"CF protection: explicitly encode invariants/constraints (skills, safety boundaries, task identity anchors) so updates cannot overwrite the stable substrate.\"\n\nacceptance_gate_invariants: \n  Every adaptation step is accepted only if coherence improves under a fixed test battery:\n  gains on the new slice + preservation of prior competencies + non-worsening error modes + bounded calibration cost.\n\nfalsifier: \n  If updates pass the acceptance gate yet a fixed regression suite still shows systematic capability loss (or drift-amplification), \n  then the Δ/GC/CF partition or invariant battery is wrong → revise the grammar, not the weights.\n\nwhy_it_matters:\n  This reframes “adaptive AI” away from neuroscience metaphors and toward falsifiable control:\n  drift becomes measurable, intervention becomes scheduled, and memory is preserved by design.\n",
    "tags": [
      "rgpx",
      "adaptive_ai",
      "drift",
      "coherence_first",
      "gradient",
      "gradient_choreography",
      "contextual_filter",
      "invariants",
      "falsifier",
      "verification_loops",
      "catastrophic_forgetting",
      "calibration_overhead",
      "routing",
      "compiling",
      "scheduling",
      "theory_gap"
    ],
    "papers": [
      "https://doi.org/10.5281/zenodo.17219414",
      "https://www.nature.com/articles/s41593-025-02169-w"
    ],
    "podcasts": [
      "https://notebooklm.google.com/notebook/54d829fa-b994-48f4-929b-d9e1990f5b25?artifactId=b7e032ef-4727-41a9-aa00-38e0b1ee7a51"
    ]
  }
}