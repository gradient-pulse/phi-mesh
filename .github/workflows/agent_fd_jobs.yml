name: Agent — FD Jobs → Pulse

on:
  push:
    paths:
      - 'inbox/fd_jobs/*.yml'
  workflow_dispatch: {}

jobs:
  agent_fd_jobs:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml numpy

      - name: Prepare folders
        run: |
          mkdir -p results/fd_probe pulse/auto inbox/fd_jobs/_done inbox/fd_jobs/_error

      - name: Process FD jobs
        env:
          PYTHONPATH: ${{ github.workspace }}
          JHTDB_OFFLINE: ${{ secrets.JHTDB_OFFLINE }}
          JHTDB_TOKEN: ${{ secrets.JHTDB_TOKEN }}
          NASA_CSV: ${{ secrets.NASA_CSV }}
        run: |
          shopt -s nullglob

          # helper: slugify "dataset-source"
          slugify () {
            # lower, replace non-safe with _, collapse _, trim _
            local s="${1,,}"
            s="$(echo -n "$s" | sed -E 's/[^a-z0-9._-]+/_/g; s/_+/_/g; s/^_+|_+$//g')"
            if [[ -z "$s" ]]; then s="dataset"; fi
            echo "$s"
          }

          for jobfile in inbox/fd_jobs/*.yml; do
            [[ -f "$jobfile" ]] || continue
            echo "→ Running job: $jobfile"

            # extract minimal fields (our controlled templates)
            dataset="$(grep -E '^dataset:' "$jobfile" | head -n1 | cut -d: -f2- | xargs)"
            if [[ -z "$dataset" ]]; then
              echo "::error ::Missing 'dataset:' in $jobfile"
              mv "$jobfile" inbox/fd_jobs/_error/ || true
              continue
            fi

            source="$(grep -E '^source:' "$jobfile" | head -n1 | cut -d: -f2- | xargs)"
            [[ -z "$source" ]] && source="synthetic"

            title="$(grep -E '^title:' "$jobfile" | head -n1 | cut -d: -f2- | xargs)"
            [[ -z "$title" ]] && title="NT Rhythm — FD Probe"

            # tags as space-separated string
            tags="$(awk '/^tags:/{f=1;next}/^[^ -]/{f=0} f && /^ *- /{sub(/^ *- /,""); printf "%s ", $0}' "$jobfile" | xargs)"

            xyz_line="$(grep -E '^xyz:' "$jobfile" | head -n1 | cut -d: -f2- | xargs)"
            win_line="$(grep -E '^window:' "$jobfile" | head -n1 | cut -d: -f2- | xargs)"
            if [[ -z "$xyz_line" || -z "$win_line" ]]; then
              echo "::error ::Missing 'xyz:' or 'window:' in $jobfile"
              mv "$jobfile" inbox/fd_jobs/_error/ || true
              continue
            fi

            base_raw="${dataset}-${source,,}"
            base="$(slugify "$base_raw")"
            today="$(date +%Y-%m-%d)"

            # allocate batchN by counting *today’s* metrics for this base
            count=$(ls "results/fd_probe/${today}_${base}_batch"*.metrics.json 2>/dev/null | wc -l | xargs)
            if [[ -z "$count" || "$count" == "0" ]]; then
              batch=1
            else
              batch=$((count + 1))
            fi

            metrics="results/fd_probe/${today}_${base}_batch${batch}.metrics.json"
            echo "  metrics → $metrics"
            echo "  dataset slug → ${base}_batch${batch}"

            # run the job → metrics
            if ! python tools/agent_rhythm/agent_fd_job_runner.py \
                  --job "$jobfile" \
                  --json-out "$metrics"; then
              echo "::error ::Job failed: $jobfile"
              mv "$jobfile" inbox/fd_jobs/_error/ || true
              continue
            fi

            # emit pulse (force dataset to carry _batchN)
            if ! python tools/agent_rhythm/make_pulse.py \
                  --metrics "$metrics" \
                  --title "$title" \
                  --dataset "${base}_batch${batch}" \
                  --tags "$tags" \
                  --outdir pulse/auto; then
              echo "::error ::Pulse emission failed: $jobfile"
              mv "$jobfile" inbox/fd_jobs/_error/ || true
              continue
            fi

            mv "$jobfile" inbox/fd_jobs/_done/ || true
          done

      - name: Rebuild maps
        run: |
          python generate_graph_data.py \
            --pulse-glob "pulse/**/*.yml" \
            --alias-map meta/aliases.yml \
            --tag-descriptions meta/tag_descriptions.yml \
            --out-js docs/data.js

      - name: Commit updated results & pulses
        run: |
          git config user.name "phi-mesh-bot"
          git config user.email "bot@phi-mesh.local"
          git add results/fd_probe/ pulse/auto/ docs/data.js inbox/fd_jobs/_done/ inbox/fd_jobs/_error/
          git commit -m "auto: Agent FD jobs → pulses (batchN) + updated maps" || echo "No changes"
          git push || true
