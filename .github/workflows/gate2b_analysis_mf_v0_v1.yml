name: "Gate 2B Analysis — MF V0+V1 (cohort compare)"

on:
  workflow_dispatch:
    inputs:
      analysis_script:
        description: "Path to analysis python script"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/tools/gate2b_mf_analysis_v1.py"

      out_dir:
        description: "Output folder for analysis artifacts (relative path)"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_analysis/mf_v0_v1"

      observed_post_dir:
        description: "Postprocess folder for observed cohort"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_postprocess/observed_planck_pr3__mf_v0_v1"

      gaussian_post_dir:
        description: "Postprocess folder for gaussian cohort"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_postprocess/gaussian_synalm_from_(dat_minus_mf)_cl"

      lcdm_post_dir:
        description: "Postprocess folder for lcdm recon cohort"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_postprocess/decision_gate_2b__lcdm_recon__mf_v0_v1"

      dedupe:
        description: "Deduplication mode inside analysis script (newest = preferred; none = include everything)"
        required: true
        type: choice
        default: "newest"
        options:
          - newest
          - none

      z_min_std:
        description: "Guard z-scores: if control std < this threshold, z-score is blank"
        required: false
        default: "1e-6"

      # Hygiene filter applied ONLY to the Gaussian cohort tables *before* analysis runs.
      # Leave blank to disable filtering.
      gauss_seed_min:
        description: "Gaussian hygiene: keep only rows with gauss_seed >= this (blank disables)"
        required: false
        default: "910"

      gauss_seed_max:
        description: "Gaussian hygiene: keep only rows with gauss_seed <= this (blank disables)"
        required: false
        default: "949"

      commit_message:
        description: "Commit message"
        required: true
        default: "Gate 2B (MF V0+V1): analysis cohort summary"

concurrency:
  group: "gate2b-analysis-mf-v0v1"
  cancel-in-progress: false

jobs:
  analyze:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (stdlib only)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          true

      - name: Preflight — require postprocess outputs
        shell: bash
        run: |
          set -euo pipefail

          OBS_DIR="${{ inputs.observed_post_dir }}"
          GAU_DIR="${{ inputs.gaussian_post_dir }}"
          LCDM_DIR="${{ inputs.lcdm_post_dir }}"

          echo "Checking postprocess dirs exist..."
          for d in "$OBS_DIR" "$GAU_DIR" "$LCDM_DIR"; do
            if [ ! -d "$d" ]; then
              echo "ERROR: Missing postprocess directory: $d"
              exit 1
            fi
          done

          echo "Checking required files..."
          req=("gc_features_table.csv" "mf_sweep_table.csv")
          for d in "$OBS_DIR" "$GAU_DIR" "$LCDM_DIR"; do
            for f in "${req[@]}"; do
              if [ ! -f "$d/$f" ]; then
                echo "ERROR: Missing required file: $d/$f"
                exit 1
              fi
            done
          done

          echo "OK: postprocess outputs found."

      - name: Gaussian hygiene — filter to seed band (optional)
        id: gauss_filter
        shell: bash
        run: |
          set -euo pipefail

          GAU_DIR="${{ inputs.gaussian_post_dir }}"
          MIN="${{ inputs.gauss_seed_min }}"
          MAX="${{ inputs.gauss_seed_max }}"

          # If both are blank, we pass through original files.
          if [ -z "$MIN" ] && [ -z "$MAX" ]; then
            echo "No gauss seed filtering requested; using original Gaussian tables."
            echo "GAU_GC_PATH=${GAU_DIR}/gc_features_table.csv" | tee -a "$GITHUB_OUTPUT"
            echo "GAU_SWEEP_PATH=${GAU_DIR}/mf_sweep_table.csv" | tee -a "$GITHUB_OUTPUT"
            exit 0
          fi

          # Default bounds if only one side provided
          if [ -z "$MIN" ]; then MIN="0"; fi
          if [ -z "$MAX" ]; then MAX="999999"; fi

          echo "Filtering Gaussian tables to gauss_seed in [$MIN, $MAX]..."

          mkdir -p "${GAU_DIR}/_filtered"

          python - <<'PY'
          import csv, os, re, sys

          gau_dir = os.environ["GAU_DIR"]
          out_dir = os.path.join(gau_dir, "_filtered")
          os.makedirs(out_dir, exist_ok=True)

          min_seed = int(os.environ["MIN"])
          max_seed = int(os.environ["MAX"])

          gauss_re = re.compile(r"__gauss(\d+)__")

          def extract_gauss_seed(json_path: str):
            if not json_path:
              return None
            m = gauss_re.search(json_path)
            if not m:
              return None
            try:
              return int(m.group(1))
            except Exception:
              return None

          def filter_csv(in_path: str, out_path: str):
            with open(in_path, "r", encoding="utf-8", newline="") as f:
              r = csv.DictReader(f)
              rows = list(r)
              fieldnames = r.fieldnames or []
            kept = []
            dropped = 0
            for row in rows:
              gs = extract_gauss_seed((row.get("json") or "").strip())
              if gs is None:
                # Keep rows without gauss seed only if they *also* look like gaussian cohort label
                # (safe default: drop, so hygiene is strict/clean).
                dropped += 1
                continue
              if min_seed <= gs <= max_seed:
                kept.append(row)
              else:
                dropped += 1

            with open(out_path, "w", encoding="utf-8", newline="") as f:
              w = csv.DictWriter(f, fieldnames=fieldnames)
              w.writeheader()
              w.writerows(kept)

            print(f"{os.path.basename(in_path)}: kept={len(kept)} dropped={dropped}")

          filter_csv(os.path.join(gau_dir, "gc_features_table.csv"), os.path.join(out_dir, "gc_features_table.csv"))
          filter_csv(os.path.join(gau_dir, "mf_sweep_table.csv"), os.path.join(out_dir, "mf_sweep_table.csv"))

          v1 = os.path.join(gau_dir, "v1_peak_table.csv")
          if os.path.exists(v1):
            filter_csv(v1, os.path.join(out_dir, "v1_peak_table.csv"))
          PY
          PY
        env:
          GAU_DIR: ${{ inputs.gaussian_post_dir }}
          MIN: ${{ inputs.gauss_seed_min }}
          MAX: ${{ inputs.gauss_seed_max }}

      - name: Set Gaussian input paths for analysis
        id: gauss_paths
        shell: bash
        run: |
          set -euo pipefail
          GAU_DIR="${{ inputs.gaussian_post_dir }}"
          if [ -d "${GAU_DIR}/_filtered" ]; then
            echo "Using filtered Gaussian tables."
            echo "GAU_GC_PATH=${GAU_DIR}/_filtered/gc_features_table.csv" | tee -a "$GITHUB_OUTPUT"
            echo "GAU_SWEEP_PATH=${GAU_DIR}/_filtered/mf_sweep_table.csv" | tee -a "$GITHUB_OUTPUT"
          else
            echo "Using original Gaussian tables."
            echo "GAU_GC_PATH=${GAU_DIR}/gc_features_table.csv" | tee -a "$GITHUB_OUTPUT"
            echo "GAU_SWEEP_PATH=${GAU_DIR}/mf_sweep_table.csv" | tee -a "$GITHUB_OUTPUT"
          fi

      - name: Run analysis
        shell: bash
        run: |
          set -euo pipefail

          TOOL="${{ inputs.analysis_script }}"
          OUT="${{ inputs.out_dir }}"

          OBS_GC="${{ inputs.observed_post_dir }}/gc_features_table.csv"
          LCDM_GC="${{ inputs.lcdm_post_dir }}/gc_features_table.csv"

          GAU_GC="${{ steps.gauss_paths.outputs.GAU_GC_PATH }}"

          DEDUPE="${{ inputs.dedupe }}"
          Z_MIN_STD="${{ inputs.z_min_std }}"

          echo "TOOL=$TOOL"
          echo "OUT=$OUT"
          echo "OBS_GC=$OBS_GC"
          echo "GAU_GC=$GAU_GC"
          echo "LCDM_GC=$LCDM_GC"
          echo "DEDUPE=$DEDUPE"
          echo "Z_MIN_STD=$Z_MIN_STD"

          if [ ! -f "$TOOL" ]; then
            echo "ERROR: analysis script not found: $TOOL"
            exit 1
          fi

          mkdir -p "$OUT"

          python "$TOOL" \
            --out_dir "$OUT" \
            --observed_gc "$OBS_GC" \
            --gaussian_gc "$GAU_GC" \
            --lcdm_gc "$LCDM_GC" \
            --dedupe "$DEDUPE" \
            --z_min_std "$Z_MIN_STD"

          echo "Analysis outputs:"
          find "$OUT" -maxdepth 2 -type f -print

      - name: Commit analysis outputs
        shell: bash
        run: |
          set -euo pipefail
          OUT="${{ inputs.out_dir }}"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add "$OUT" || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "${{ inputs.commit_message }}"
          git push
