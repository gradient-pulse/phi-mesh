name: "Gate 2B Analysis — MF V0+V1 (cohort compare)"

# Intended to be run AFTER:
#   - "Gate 2B Postprocess — MF V0+V1 (sweep table + V1 peak)"
#
# Optional auto-trigger (leave commented unless you want it):
#
# on:
#   workflow_run:
#     workflows: ["Gate 2B Postprocess — MF V0+V1 (sweep table + V1 peak)"]
#     types: [completed]

on:
  workflow_dispatch:
    inputs:
      analysis_script:
        description: "Path to analysis python script"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/tools/gate2b_mf_analysis_v1.py"
      out_dir:
        description: "Output folder for analysis artifacts (relative path)"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_analysis/mf_v0_v1"
      observed_post_dir:
        description: "Postprocess folder for observed cohort"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_postprocess/observed_planck_pr3__mf_v0_v1"
      gaussian_post_dir:
        description: "Postprocess folder for gaussian cohort"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_postprocess/gaussian_synalm_from_(dat_minus_mf)_cl"
      lcdm_post_dir:
        description: "Postprocess folder for lcdm recon cohort"
        required: true
        default: "experiments/rgpx_proof_proto/cmb_phase_dagger/results/topology_mf_v0_v1/controls/_postprocess/decision_gate_2b__lcdm_recon__mf_v0_v1"

      # Hygiene switch: filter Gaussian cohort to a clean gauss_seed band (recommended for explainability)
      filter_gaussian:
        description: "Filter Gaussian cohort to gauss_seed range before analysis?"
        required: true
        type: choice
        default: "yes"
        options:
          - "yes"
          - "no"
      gauss_seed_min:
        description: "Min gauss_seed to keep (only used if filter_gaussian=yes)"
        required: true
        default: "910"
      gauss_seed_max:
        description: "Max gauss_seed to keep (only used if filter_gaussian=yes)"
        required: true
        default: "949"

      dedupe:
        description: "Deduplication mode inside analysis script"
        required: true
        type: choice
        default: "newest"
        options:
          - newest
          - none

      commit_message:
        description: "Commit message"
        required: true
        default: "Gate 2B (MF V0+V1): analysis cohort summary"

concurrency:
  group: "gate2b-analysis-mf-v0v1"
  cancel-in-progress: false

jobs:
  analyze:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (minimal)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          # analysis script uses stdlib only; numpy not required
          true

      - name: Preflight — require postprocess outputs
        shell: bash
        run: |
          set -euo pipefail

          OBS_DIR="${{ inputs.observed_post_dir }}"
          GAU_DIR="${{ inputs.gaussian_post_dir }}"
          LCDM_DIR="${{ inputs.lcdm_post_dir }}"

          echo "Checking postprocess dirs exist..."
          for d in "$OBS_DIR" "$GAU_DIR" "$LCDM_DIR"; do
            if [ ! -d "$d" ]; then
              echo "ERROR: Missing postprocess directory: $d"
              echo "Run the postprocess workflow first."
              exit 1
            fi
          done

          echo "Checking required files..."
          req=("gc_features_table.csv" "mf_sweep_table.csv")
          for d in "$OBS_DIR" "$GAU_DIR" "$LCDM_DIR"; do
            for f in "${req[@]}"; do
              if [ ! -f "$d/$f" ]; then
                echo "ERROR: Missing required file: $d/$f"
                echo "Run the postprocess workflow first (or ensure it wrote this file)."
                exit 1
              fi
            done
          done

          echo "OK: postprocess outputs found."

      - name: Gaussian hygiene — optional filter to gauss_seed band
        shell: bash
        env:
          GAU_DIR: ${{ inputs.gaussian_post_dir }}
          FILTER_ON: ${{ inputs.filter_gaussian }}
          MIN: ${{ inputs.gauss_seed_min }}
          MAX: ${{ inputs.gauss_seed_max }}
        run: |
          set -euo pipefail

          if [ "${FILTER_ON}" != "yes" ]; then
            echo "Gaussian filtering disabled (filter_gaussian=no)."
            exit 0
          fi

          FILTER_DIR="${GAU_DIR}/_filtered_gauss_seed_${MIN}_${MAX}"
          echo "Filtering Gaussian tables to gauss_seed in [${MIN}, ${MAX}]..."
          echo "GAU_DIR=${GAU_DIR}"
          echo "FILTER_DIR=${FILTER_DIR}"

          mkdir -p "${FILTER_DIR}"

          python - <<'PY'
          import csv, os, re, shutil, sys

          GAU_DIR   = os.environ["GAU_DIR"]
          MIN_SEED  = int(os.environ["MIN"])
          MAX_SEED  = int(os.environ["MAX"])
          FILTER_DIR= os.path.join(GAU_DIR, f"_filtered_gauss_seed_{MIN_SEED}_{MAX_SEED}")

          gauss_re = re.compile(r"__gauss(\d+)__")

          def extract_gauss_seed(row):
            j = (row.get("json") or "").strip()
            if not j:
              return None
            m = gauss_re.search(j)
            if not m:
              return None
            try:
              return int(m.group(1))
            except Exception:
              return None

          def filter_csv(src, dst):
            with open(src, "r", encoding="utf-8", newline="") as f:
              reader = csv.DictReader(f)
              rows = list(reader)
              fieldnames = reader.fieldnames or []

            kept, dropped = [], 0
            for r in rows:
              gs = extract_gauss_seed(r)
              # Keep rows that do not look like gaussian rows (defensive), OR within band.
              if gs is None or (MIN_SEED <= gs <= MAX_SEED):
                kept.append(r)
              else:
                dropped += 1

            os.makedirs(os.path.dirname(dst), exist_ok=True)
            with open(dst, "w", encoding="utf-8", newline="") as f:
              w = csv.DictWriter(f, fieldnames=fieldnames)
              w.writeheader()
              w.writerows(kept)

            return len(kept), dropped

          for fn in ["gc_features_table.csv", "mf_sweep_table.csv", "v1_peak_table.csv"]:
            src = os.path.join(GAU_DIR, fn)
            dst = os.path.join(FILTER_DIR, fn)
            if not os.path.exists(src):
              print(f"[WARN] Missing {src} (skip)")
              continue
            kept, dropped = filter_csv(src, dst)
            print(f"{fn}: kept={kept} dropped={dropped}")

          # Copy markdown tables if present (no filtering; just convenience)
          for md in ["mf_sweep_table.md", "v1_peak_table.md", "gc_features_table.md"]:
            src = os.path.join(GAU_DIR, md)
            if os.path.exists(src):
              shutil.copy2(src, os.path.join(FILTER_DIR, md))
          PY

          echo "Filtered outputs written to: ${FILTER_DIR}"
          ls -lh "${FILTER_DIR}" || true

      - name: Run analysis
        shell: bash
        run: |
          set -euo pipefail

          TOOL="${{ inputs.analysis_script }}"
          OUT="${{ inputs.out_dir }}"

          OBS_GC="${{ inputs.observed_post_dir }}/gc_features_table.csv"
          LCDM_GC="${{ inputs.lcdm_post_dir }}/gc_features_table.csv"

          DEDUPE="${{ inputs.dedupe }}"

          # If filtered Gaussian dir exists (and filter_gaussian=yes), use it; else use original.
          GAU_DIR="${{ inputs.gaussian_post_dir }}"
          MIN="${{ inputs.gauss_seed_min }}"
          MAX="${{ inputs.gauss_seed_max }}"
          FILTER_ON="${{ inputs.filter_gaussian }}"
          GAU_FILTER_DIR="${GAU_DIR}/_filtered_gauss_seed_${MIN}_${MAX}"

          if [ "${FILTER_ON}" = "yes" ] && [ -f "${GAU_FILTER_DIR}/gc_features_table.csv" ]; then
            GAU_GC="${GAU_FILTER_DIR}/gc_features_table.csv"
            echo "Using FILTERED Gaussian cohort: ${GAU_GC}"
          else
            GAU_GC="${GAU_DIR}/gc_features_table.csv"
            echo "Using FULL Gaussian cohort: ${GAU_GC}"
          fi

          echo "TOOL=$TOOL"
          echo "OUT=$OUT"
          echo "OBS_GC=$OBS_GC"
          echo "GAU_GC=$GAU_GC"
          echo "LCDM_GC=$LCDM_GC"
          echo "DEDUPE=$DEDUPE"

          if [ ! -f "$TOOL" ]; then
            echo "ERROR: analysis script not found: $TOOL"
            exit 1
          fi

          mkdir -p "$OUT"

          python "$TOOL" \
            --out_dir "$OUT" \
            --observed_gc "$OBS_GC" \
            --gaussian_gc "$GAU_GC" \
            --lcdm_gc "$LCDM_GC" \
            --dedupe "$DEDUPE"

          echo "Analysis outputs:"
          find "$OUT" -maxdepth 2 -type f -print

      - name: Commit analysis outputs
        shell: bash
        run: |
          set -euo pipefail

          OUT="${{ inputs.out_dir }}"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add "$OUT" || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "${{ inputs.commit_message }}"
          git push
