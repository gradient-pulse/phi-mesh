name: FD probe (isotropic1024coarse → metrics + pulse)

on:
  workflow_dispatch:
    inputs:
      source:
        description: "synthetic | jhtdb | nasa"
        required: true
        default: "jhtdb"
      dataset:
        description: "dataset name/slug or path (free text; will be auto-sanitized)"
        required: true
        default: "isotropic1024coarse"
      var:
        description: "variable name"
        required: true
        default: "u"
      xyz:
        description: "probe point as x,y,z"
        required: true
        default: "0.1,0.1,0.1"
      twin:
        description: "time window as t0,t1,dt"
        required: true
        default: "0.0,1.0,0.0005"
      title:
        description: "pulse title"
        required: true
        default: "NT Rhythm — FD Probe"
      tags:
        description: "space-separated tags"
        required: true
        default: "nt_rhythm turbulence navier_stokes rgp"
      smooth_k:
        description: "moving-average window on |u| (0 disables)"
        required: false
        default: "5"
      peak_mag_k:
        description: "magnitude threshold = mu + k*sig"
        required: false
        default: "0.75"
      peak_prom_k:
        description: "prominence proxy = k*sig"
        required: false
        default: "0.25"
      min_sep_ms:
        description: "min separation between events in milliseconds"
        required: false
        default: "2.0"

permissions:
  contents: write

jobs:
  fd-probe:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml numpy

      - name: Normalize inputs and compute batch label
        id: prep
        shell: bash
        env:
          SRC: ${{ github.event.inputs.source }}
          DATASET: ${{ github.event.inputs.dataset }}
        run: |
          set -euo pipefail

          # sanitize dataset to slug
          py='import re,sys; s=sys.argv[1].strip().lower(); s=re.sub(r"[^a-z0-9._-]+","_",s); s=re.sub(r"_+","_",s).strip("_"); print(s or "dataset")'
          DS_SLUG=$(python -c "$py" "$DATASET")

          # source slug
          SRC_SLUG=$(echo "${SRC}" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9._-]/_/g')

          # base name WITHOUT batch; we will add batchN below
          BASE="${DS_SLUG}_${SRC_SLUG}"

          mkdir -p results/fd_probe

          # find next batchN for this BASE
          NEXT=1
          shopt -s nullglob
          existing=(results/fd_probe/${BASE}_batch*.metrics.json)
          if [[ ${#existing[@]} -gt 0 ]]; then
            last=$(ls -1 results/fd_probe/${BASE}_batch*.metrics.json | sed -E 's/.*_batch([0-9]+)\.metrics\.json/\1/' | sort -n | tail -1)
            NEXT=$(( last + 1 ))
          fi

          METRICS="results/fd_probe/${BASE}_batch${NEXT}.metrics.json"

          echo "base=${BASE}" >> "$GITHUB_OUTPUT"
          echo "batch=${NEXT}" >> "$GITHUB_OUTPUT"
          echo "metrics_path=${METRICS}" >> "$GITHUB_OUTPUT"

          echo "::notice title=Batch::Using ${BASE}_batch${NEXT}"

      - name: Run FD probe
        env:
          NASA_CSV: ${{ secrets.NASA_CSV }}
          JHTDB_TOKEN: ${{ secrets.JHTDB_TOKEN }}
        run: |
          set -euo pipefail
          python tools/fd_connectors/run_fd_probe.py \
            --source "${{ github.event.inputs.source }}" \
            --dataset "${{ github.event.inputs.dataset }}" \
            --var "${{ github.event.inputs.var }}" \
            --xyz "${{ github.event.inputs.xyz }}" \
            --twin "${{ github.event.inputs.twin }}" \
            --json-out "${{ steps.prep.outputs.metrics_path }}" \
            --title "${{ github.event.inputs.title }}" \
            --tags "${{ github.event.inputs.tags }}" \
            --smooth-k "${{ github.event.inputs.smooth_k }}" \
            --peak-mag-k "${{ github.event.inputs.peak_mag_k }}" \
            --peak-prom-k "${{ github.event.inputs.peak_prom_k }}" \
            --min-sep-ms "${{ github.event.inputs.min_sep_ms }}"

      - name: Emit pulse (always with exact batch label)
        run: |
          set -euo pipefail
          METRICS="${{ steps.prep.outputs.metrics_path }}"
          # slug for pulse filename = metrics basename without extension
          PULSE_SLUG=$(basename "$METRICS")
          PULSE_SLUG="${PULSE_SLUG%.metrics.json}"  # drop suffix

          python tools/agent_rhythm/make_pulse.py \
            --metrics "$METRICS" \
            --title "${{ github.event.inputs.title }}" \
            --dataset "$PULSE_SLUG" \
            --tags "${{ github.event.inputs.tags }}" \
            --outdir "pulse/auto"

      - name: Commit results + pulse + maps
        run: |
          set -euo pipefail
          git config user.name "phi-mesh-bot"
          git config user.email "actions@users.noreply.github.com"
          git add results/fd_probe/*.json pulse/auto/*.yml
          git add maps/* || true
          git commit -m "auto: FD probe (${{ steps.prep.outputs.base }}_batch${{ steps.prep.outputs.batch }}) pulse + updated maps" || echo "Nothing to commit"
          git push
