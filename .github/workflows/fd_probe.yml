name: NT Rhythm — FD Probe to Pulse

on:
  workflow_dispatch:
    inputs:
      source:
        description: 'Data source (synthetic | jhtdb | nasa)'
        required: true
        default: 'synthetic'
      dataset:
        description: 'Dataset name/slug (free text — will be sanitized)'
        required: true
        default: 'demo'
      var:
        description: 'Variable'
        required: true
        default: 'u'
      xyz:
        description: 'Probe point as x,y,z'
        required: true
        default: '0.1,0.1,0.1'
      twin:
        description: 'Time window as t0,t1,dt'
        required: true
        default: '0.0,10.0,0.01'
      title:
        description: 'Pulse title'
        required: true
        default: 'NT Rhythm — FD Probe'
      tags:
        description: 'Space-separated tags'
        required: true
        default: 'nt_rhythm turbulence navier_stokes rgp'

permissions:
  contents: write

jobs:
  probe:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip pyyaml numpy

      # Sanitize dataset -> slug, pick next batchN by scanning results/fd_probe
      - name: Resolve slug + next batch
        id: meta
        shell: python
        run: |
          import os, re, glob, json, sys, pathlib
          WS   = os.environ["GITHUB_WORKSPACE"]
          SRC  = os.environ["IN_SOURCE"].strip().lower()
          DSIN = os.environ["IN_DATASET"].strip()
          def safe_slug(s:str)->str:
              s = re.sub(r"[^a-z0-9._-]+","_", s.strip().lower())
              s = re.sub(r"_+","_", s).strip("_")
              return s or "dataset"
          slug = safe_slug(DSIN)
          # scan existing results for this slug+source
          res_dir = pathlib.Path(WS) / "results" / "fd_probe"
          res_dir.mkdir(parents=True, exist_ok=True)
          pat = str(res_dir / f"{slug}_{SRC}_batch*.metrics.json")
          batches = []
          for p in glob.glob(pat):
              m = re.search(r"_batch(\d+)\.metrics\.json$", p)
              if m: batches.append(int(m.group(1)))
          next_batch = (max(batches) + 1) if batches else 1
          json_out = str(res_dir / f"{slug}_{SRC}_batch{next_batch}.metrics.json")
          # dataset slug we pass to make_pulse so pulse filename includes batchN
          dataset_with_batch = f"{slug}_{SRC}_batch{next_batch}"
          print(f"::notice::slug={slug} source={SRC} batch={next_batch}")
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"slug={slug}\n")
              f.write(f"source={SRC}\n")
              f.write(f"batch={next_batch}\n")
              f.write(f"json_out={json_out}\n")
              f.write(f"dataset_with_batch={dataset_with_batch}\n")
        env:
          IN_SOURCE:  ${{ github.event.inputs.source }}
          IN_DATASET: ${{ github.event.inputs.dataset }}

      - name: Run FD probe
        env:
          PYTHONPATH: ${{ github.workspace }}
          JHTDB_OFFLINE: ${{ secrets.JHTDB_OFFLINE }}
          JHTDB_TOKEN:   ${{ secrets.JHTDB_TOKEN }}
          NASA_CSV:      ${{ secrets.NASA_CSV }}
        run: |
          python tools/fd_connectors/run_fd_probe.py \
            --source   "${{ steps.meta.outputs.source }}" \
            --dataset  "${{ steps.meta.outputs.slug }}" \
            --var      "${{ github.event.inputs.var }}" \
            --xyz      "${{ github.event.inputs.xyz }}" \
            --twin     "${{ github.event.inputs.twin }}" \
            --json-out "${{ steps.meta.outputs.json_out }}"

      - name: Emit pulse YAML
        run: |
          python tools/agent_rhythm/make_pulse.py \
            --metrics "${{ steps.meta.outputs.json_out }}" \
            --title   "${{ github.event.inputs.title }}" \
            --dataset "${{ steps.meta.outputs.dataset_with_batch }}" \
            --tags    "${{ github.event.inputs.tags }}" \
            --outdir  pulse/auto

      - name: Rebuild maps
        run: |
          python generate_graph_data.py \
            --pulse-glob "pulse/**/*.yml" \
            --alias-map meta/aliases.yml \
            --tag-descriptions meta/tag_descriptions.yml \
            --out-js docs/data.js

      - name: Commit & push
        run: |
          git config user.name "phi-mesh-bot"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          git commit -m "auto: FD probe ${{ steps.meta.outputs.slug }} (${{
            steps.meta.outputs.source }}, batch${{ steps.meta.outputs.batch }}) → metrics + pulse + maps" || echo "nothing to commit"
          git push || true
