name: NT Rhythm — FD Probe to Pulse

on:
  workflow_dispatch:
    inputs:
      source:
        description: 'Data source (synthetic | jhtdb | nasa)'
        required: true
        default: 'synthetic'
      dataset:
        description: 'Dataset name/slug or path (free text; will be auto-sanitized)'
        required: true
        default: 'demo'
      var:
        description: 'Variable name'
        required: true
        default: 'u'
      xyz:
        description: 'Probe point as x,y,z'
        required: true
        default: '0.1,0.1,0.1'
      twin:
        description: 'Time window as t0,t1,dt'
        required: true
        default: '0.0,10.0,0.01'
      title:
        description: 'Pulse title'
        required: true
        default: 'NT Rhythm — FD Probe'
      tags:
        description: 'Space-separated tags'
        required: true
        default: 'nt_rhythm turbulence navier_stokes rgp'

permissions:
  contents: write

jobs:
  probe:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip pyyaml numpy

      # Sanitize dataset, build base slug, and auto-assign next batchN by
      # scanning today's pulses (fallback: results/fd_probe).
      - name: Resolve slug & next batch
        id: inp
        shell: python
        run: |
          import datetime as dt, glob, os, re, sys, pathlib, json

          def safe_slug(s:str)->str:
              s = (s or "").strip().lower()
              s = re.sub(r"[^a-z0-9._-]+","_", s)
              s = re.sub(r"_+","_", s).strip("_")
              return s or "dataset"

          source   = os.environ["SRC_IN"].strip().lower()
          dataset  = os.environ["DS_IN"].strip()
          var      = os.environ["VAR_IN"].strip()
          xyz      = os.environ["XYZ_IN"].strip()
          twin     = os.environ["TWIN_IN"].strip()

          # base slug = sanitized dataset + source-tag (except synthetic already includes it in title nicely)
          base = safe_slug(dataset)
          if source in ("nasa","jhtdb"):
              base = f"{base}-{source}"
          elif source == "synthetic":
              base = f"{base}_synthetic"

          today = dt.date.today().isoformat()
          pulses_pat  = f"pulse/auto/{today}_{base}_batch*.yml"
          results_pat = f"results/fd_probe/{base}_batch*.metrics.json"

          def next_batch():
              nums = []
              for path in glob.glob(pulses_pat):
                  m = re.search(r"_batch(\d+)\.yml$", path)
                  if m: nums.append(int(m.group(1)))
              if not nums:  # look in results if pulses absent (first run today)
                  for path in glob.glob(results_pat):
                      m = re.search(r"_batch(\d+)\.metrics\.json$", path)
                      if m: nums.append(int(m.group(1)))
              return (max(nums) + 1) if nums else 1

          b = next_batch()
          combined = f"{base}_batch{b}"

          # outputs
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"base={base}\n")
              f.write(f"batch={b}\n")
              f.write(f"slug={combined}\n")
              f.write(f"today={today}\n")

          print(f"::notice::Using slug={combined} (auto batch {b})")

        env:
          SRC_IN:  ${{ github.event.inputs.source }}
          DS_IN:   ${{ github.event.inputs.dataset }}
          VAR_IN:  ${{ github.event.inputs.var }}
          XYZ_IN:  ${{ github.event.inputs.xyz }}
          TWIN_IN: ${{ github.event.inputs.twin }}

      - name: Run FD probe
        env:
          PYTHONPATH: ${{ github.workspace }}
          JHTDB_OFFLINE: ${{ secrets.JHTDB_OFFLINE }}
          JHTDB_TOKEN:   ${{ secrets.JHTDB_TOKEN }}
          NASA_CSV:      ${{ github.event.inputs.dataset }}  # for nasa, local path/URL works; ignored by others
        run: |
          mkdir -p results/fd_probe
          python tools/fd_connectors/run_fd_probe.py \
            --source "${{ github.event.inputs.source }}" \
            --dataset "${{ steps.inp.outputs.slug }}" \
            --var "${{ github.event.inputs.var }}" \
            --xyz "${{ github.event.inputs.xyz }}" \
            --twin "${{ github.event.inputs.twin }}" \
            --json-out "results/fd_probe/${{ steps.inp.outputs.slug }}.metrics.json"

      - name: Emit pulse YAML
        run: |
          python tools/agent_rhythm/make_pulse.py \
            --metrics "results/fd_probe/${{ steps.inp.outputs.slug }}.metrics.json" \
            --title   "${{ github.event.inputs.title }}" \
            --dataset "${{ steps.inp.outputs.slug }}" \
            --tags    "${{ github.event.inputs.tags }}" \
            --outdir  pulse/auto

      - name: Rebuild Tag/Gradient maps
        run: |
          python generate_graph_data.py \
            --pulse-glob "pulse/**/*.yml" \
            --alias-map meta/aliases.yml \
            --tag-descriptions meta/tag_descriptions.yml \
            --out-js docs/data.js

      - name: Commit & push
        run: |
          git config user.name "phi-mesh-bot"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          git commit -m "auto: FD probe (${{ steps.inp.outputs.slug }}) pulse + updated maps" || echo "nothing to commit"
          git push || true
