name: NT Rhythm — FD Probe to Pulse

on:
  workflow_dispatch:
    inputs:
      source:
        description: 'Data source (synthetic | jhtdb | nasa)'
        required: true
        default: 'synthetic'
      dataset:
        description: 'Dataset name/slug or path (free text; will be auto-sanitized)'
        required: true
        default: 'demo'
      var:
        description: 'Variable name'
        required: true
        default: 'u'
      xyz:
        description: 'Probe point as x,y,z'
        required: true
        default: '0.1,0.1,0.1'
      twin:
        description: 'Time window as t0,t1,dt'
        required: true
        default: '0.0,10.0,0.01'
      batch:
        description: 'Batch label for repeat runs (e.g., batch1, batch2)'
        required: true
        default: 'batch1'
      title:
        description: 'Pulse title'
        required: true
        default: 'NT Rhythm — FD Probe'
      tags:
        description: 'Space-separated tags'
        required: true
        default: 'nt_rhythm turbulence navier_stokes rgp'

permissions:
  contents: write

jobs:
  probe:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip pyyaml numpy

      # Sanitize dataset -> slug, and validate basic shapes.
      - name: Resolve & validate inputs
        id: inp
        shell: python
        run: |
          import os, re, sys

          def safe_slug(s:str)->str:
              s = (s or "").strip().lower()
              s = re.sub(r"[^a-z0-9._-]+","_", s)
              s = re.sub(r"_+","_", s).strip("_")
              return s or "dataset"

          def parse_triplet(s:str):
              parts = [p.strip() for p in (s or "").split(",")]
              if len(parts) != 3:
                  raise SystemExit(f"Bad triplet (need 3 comma-separated numbers): {s!r}")
              return parts

          ds_in   = os.environ["DATASET_IN"]
          xyz_in  = os.environ["XYZ_IN"]
          twin_in = os.environ["TWIN_IN"]
          source  = os.environ["SRC_IN"].strip().lower()
          batch   = os.environ["BATCH_IN"].strip() or "batch1"

          # Basic validation (content further checked by the probe script)
          _ = parse_triplet(xyz_in)
          _ = parse_triplet(twin_in)

          slug = safe_slug(ds_in)

          # Compose names used elsewhere
          # - result base: <slug>_<source>_<batch>
          # - pulse dataset: <slug>-<source>_<batch>  (hyphen before source, underscore before batch)
          result_base = f"{slug}_{source}_{batch}"
          pulse_dataset = f"{slug}-{source}_{batch}"

          print(f"::notice::Using dataset slug = {slug}, source = {source}, batch = {batch}")
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"slug={slug}\n")
              f.write(f"source={source}\n")
              f.write(f"batch={batch}\n")
              f.write(f"result_base={result_base}\n")
              f.write(f"pulse_dataset={pulse_dataset}\n")
        env:
          DATASET_IN: ${{ github.event.inputs.dataset }}
          XYZ_IN:     ${{ github.event.inputs.xyz }}
          TWIN_IN:    ${{ github.event.inputs.twin }}
          SRC_IN:     ${{ github.event.inputs.source }}
          BATCH_IN:   ${{ github.event.inputs.batch }}

      - name: Run FD probe
        env:
          PYTHONPATH:    ${{ github.workspace }}
          JHTDB_OFFLINE: ${{ secrets.JHTDB_OFFLINE }}
          JHTDB_TOKEN:   ${{ secrets.JHTDB_TOKEN }}
          NASA_CSV:      ${{ secrets.NASA_CSV }}
        run: |
          set -euo pipefail
          mkdir -p results/fd_probe
          python tools/fd_connectors/run_fd_probe.py \
            --source   "${{ steps.inp.outputs.source }}" \
            --dataset  "${{ steps.inp.outputs.slug }}" \
            --var      "${{ github.event.inputs.var }}" \
            --xyz      "${{ github.event.inputs.xyz }}" \
            --twin     "${{ github.event.inputs.twin }}" \
            --batch    "${{ steps.inp.outputs.batch }}" \
            --json-out "results/fd_probe/${{ steps.inp.outputs.result_base }}.metrics.json"

      - name: Emit pulse YAML
        run: |
          python tools/agent_rhythm/make_pulse.py \
            --metrics "results/fd_probe/${{ steps.inp.outputs.result_base }}.metrics.json" \
            --title   "${{ github.event.inputs.title }}" \
            --dataset "${{ steps.inp.outputs.pulse_dataset }}" \
            --tags    "${{ github.event.inputs.tags }}" \
            --outdir  pulse/auto

      - name: Rebuild maps
        run: |
          python generate_graph_data.py \
            --pulse-glob "pulse/**/*.yml" \
            --alias-map meta/aliases.yml \
            --tag-descriptions meta/tag_descriptions.yml \
            --out-js docs/data.js

      - name: Commit & push
        run: |
          git config user.name "phi-mesh-bot"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          git commit -m "auto: FD probe (${{ steps.inp.outputs.result_base }}) pulse + updated maps" || echo "nothing to commit"
          git push || true
