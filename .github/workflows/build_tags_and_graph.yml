name: Build Tags & Graph
# excludes archived + auto pulses
on:
  push:
    branches: [ main ]
    paths:
      - 'pulse/**/*.yml'
      - 'meta/aliases.yml'
      - 'meta/tag_descriptions.yml'
      - 'generate_graph_data.py'
      - '.github/workflows/build_tags_and_graph.yml'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: build-tags-and-graph
  cancel-in-progress: true

jobs:
  build:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      # Build view = ONLY top-level pulses (no archive dir, no auto dir)
      - name: Prepare pulse build view (exclude archive & auto)
        shell: bash
        run: |
          set -euo pipefail
          rm -rf pulse/_buildview
          mkdir -p pulse/_buildview
          shopt -s nullglob
          for f in pulse/*.yml; do
            ln -s "../$(basename "$f")" "pulse/_buildview/$(basename "$f")" || true
          done
          echo "---- buildview contents ----"
          ls -la pulse/_buildview || true

      # Quick canary to ensure expected generator symbol exists
      - name: Generator canary (canon_tag present)
        shell: bash
        run: |
          set -euo pipefail
          printf "import pathlib,sys\np=pathlib.Path('generate_graph_data.py').read_text(encoding='utf-8')\nok='def canon_tag(' in p\nprint('[GEN] canon_tag present:', ok)\nraise SystemExit(0 if ok else 3)\n" > .canary.py
          python .canary.py

      - name: Force root generator and bust cache
        shell: bash
        run: |
          set -euo pipefail
          if [ -f tools/generate_graph_data.py ]; then
            printf "import subprocess, sys\nsys.exit(subprocess.call([sys.executable, 'generate_graph_data.py', *sys.argv[1:]]))\n" > tools/generate_graph_data.py
          fi
          rm -f docs/data.js

      # Lint YAML + dates before generation (prevents timeline stalls)
      - name: Lint pulses (YAML + required fields)
        shell: bash
        run: |
          set -euo pipefail
          cat > .lint_pulses.py <<'PY'
import sys, re, glob, yaml
bad = 0
iso = re.compile(r'^\d{4}-\d{2}-\d{2}$')
for path in sorted(glob.glob('pulse/_buildview/*.yml')):
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
    except Exception as e:
        print(f"❌ YAML parse error in {path}: {e}")
        bad += 1
        continue
    if not data:
        print(f"❌ Empty YAML in {path}")
        bad += 1
        continue
    for k in ('title','date','tags'):
        if k not in data:
            print(f"❌ Missing '{k}' in {path}")
            bad += 1
    d = str(data.get('date',''))
    if not iso.match(d):
        print(f"❌ Bad date '{d}' in {path} (YYYY-MM-DD expected)")
        bad += 1
if bad:
    print(f"FAILED: {bad} problems.")
    sys.exit(2)
print('✅ Pulses validated.')
PY
          python .lint_pulses.py

      - name: Generate docs/data.js
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p docs
          python generate_graph_data.py \
            --pulse-glob "pulse/_buildview/*.yml" \
            --alias-map meta/aliases.yml \
            --tag-descriptions meta/tag_descriptions.yml \
            --out-js docs/data.js

      - name: Validate data.js
        shell: bash
        run: |
          set -euo pipefail
          test -s docs/data.js || (echo "ERROR: docs/data.js is empty" && exit 2)
          head -n 1 docs/data.js | grep -q "window.PHI_DATA" || (echo "ERROR: data.js missing window.PHI_DATA" && exit 3)
          echo "OK: docs/data.js looks good."

      - name: Audit for case-insensitive duplicate tags
        shell: bash
        run: |
          set -euo pipefail
          printf "import json,re,collections,sys\n" \
                 "txt=open('docs/data.js','r',encoding='utf-8').read()\n" \
                 "m=re.search(r\"window\\.PHI_DATA\\s*=\\s*(\\{.*\\});\\s*$\",txt,re.S)\n" \
                 "data=json.loads(m.group(1)) if m else (_ for _ in ()).throw(SystemExit(4))\n" \
                 "ids=[n.get('id','') for n in data.get('nodes',[])]\n" \
                 "by=collections.defaultdict(list)\n" \
                 "[by[t.lower()].append(t) for t in ids]\n" \
                 "dupes={k:v for k,v in by.items() if len(v)>1}\n" \
                 "import pprint\n" \
                 "if dupes:\n" \
                 "  print('❌ case-insensitive duplicates detected:')\n" \
                 "  [print(' ',k,'=>',v) for k,v in sorted(dupes.items())]\n" \
                 "  sys.exit(5)\n" \
                 "print('✅ no case-insensitive duplicates')\n" > .audit.py
          python .audit.py

      - name: Commit generated artifacts
        shell: bash
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add docs/data.js
          git diff --cached --quiet && echo "No changes to commit" && exit 0
          git commit -m "auto: rebuild data.js (exclude auto, validated)"
          git pull --rebase origin main || true
          git push
