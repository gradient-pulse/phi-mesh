name: RGP–NS Grid (multi-probe → consolidated pulse)

on:
  workflow_dispatch:
    inputs:
      source:
        description: "synthetic | jhtdb | nasa"
        required: true
        default: "jhtdb"
      dataset:
        description: "dataset slug or path (free text; will be auto-sanitized)"
        required: true
        default: "isotropic1024coarse"
      var:
        description: "variable name"
        required: true
        default: "u"
      points:
        description: "probe points (one x,y,z per line)"
        required: true
        default: |
          0.10,0.10,0.10
          0.12,0.10,0.10
          0.10,0.12,0.10
          0.10,0.10,0.12
      twin:
        description: "time window as t0,t1,dt"
        required: true
        default: "0.0,1.2,0.0001"
      title:
        description: "Pulse title"
        required: true
        default: "NT Rhythm — RGP–NS Grid"
      tags:
        description: "Space-separated tags"
        required: true
        default: "nt_rhythm turbulence navier_stokes rgp"

permissions:
  contents: write

jobs:
  plan:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.mk.outputs.matrix }}
      base:   ${{ steps.mk.outputs.base }}
      today:  ${{ steps.mk.outputs.today }}
    steps:
      - uses: actions/checkout@v4

      - id: mk
        shell: bash
        env:
          SRC: ${{ github.event.inputs.source }}
          DATASET: ${{ github.event.inputs.dataset }}
        run: |
          set -euo pipefail

          # Sanitize dataset to slug (one-line Python; YAML-safe)
          DS_SLUG=$(python -c 'import re,sys; s=sys.argv[1].strip().lower(); s=re.sub(r"[^a-z0-9._-]+","_",s); s=re.sub(r"_+","_",s).strip("_"); print(s or "dataset")' "$DATASET")

          # Source slug
          SRC_SLUG=$(echo "${SRC}" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9._-]/_/g')

          # Base slug (no date, no batch)
          BASE="${DS_SLUG}_${SRC_SLUG}"

          # Matrix JSON from multi-line "points" input (one x,y,z per line)
          MATRIX=$(jq -R -s 'split("\n") | map(select(length>0))' <<< "${{ github.event.inputs.points }}")

          echo "matrix=${MATRIX}"       >> "$GITHUB_OUTPUT"
          echo "base=${BASE}"           >> "$GITHUB_OUTPUT"
          echo "today=$(date -u +%F)"   >> "$GITHUB_OUTPUT"

  run-grid:
    needs: plan
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        xyz: ${{ fromJson(needs.plan.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install numpy pyyaml

      - name: Run agent shard
        env:
          PYTHONPATH: ${{ github.workspace }}
          JHTDB_TOKEN: ${{ secrets.JHTDB_TOKEN }}
          NASA_CSV:    ${{ secrets.NASA_CSV }}
          SRC:         ${{ github.event.inputs.source }}
          DATASET:     ${{ github.event.inputs.dataset }}
          VAR:         ${{ github.event.inputs.var }}
          XYZ:         ${{ matrix.xyz }}
          TWIN:        ${{ github.event.inputs.twin }}
          STAGE:       results/rgp_ns/grid/${{ github.run_id }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$STAGE"

          # Convert "x,y,z" → JSON "[x,y,z]" (single-line Python; YAML-safe)
          XYZ_JSON=$(python -c 'import sys,json; s=sys.argv[1].strip(); p=[t.strip() for t in s.split(",")]; assert len(p)==3, "xyz must be x,y,z"; print(json.dumps(p))' "$XYZ")
          echo "Shard xyz: $XYZ_JSON"

          # Run the grid wrapper (writes one metrics JSON per shard into $STAGE)
          python agents/rgp_ns/agent_grid.py \
            --source "$SRC" \
            --dataset "$DATASET" \
            --var "$VAR" \
            --xyz "$XYZ_JSON" \
            --twin "$TWIN" \
            --stage "$STAGE"

      - name: Upload shard artifacts (debug)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rgp_ns_shards_${{ matrix.xyz }}
          path: results/rgp_ns/grid/${{ github.run_id }}/*.json
          if-no-files-found: ignore

  consolidate:
    needs: [plan, run-grid]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install numpy pyyaml

      - name: Compute next daily batch + select best shard
        id: select
        shell: bash
        env:
          BASE:  ${{ needs.plan.outputs.base }}
          TODAY: ${{ needs.plan.outputs.today }}
          STAGE: results/rgp_ns/grid/${{ github.run_id }}
        run: |
          set -euo pipefail
          mkdir -p results/rgp_ns pulse/auto

          # Determine next daily batch index for grid results
          shopt -s nullglob
          existing=(results/rgp_ns/${TODAY}_${BASE}_grid_batch*.metrics.json)
          if [[ ${#existing[@]} -gt 0 ]]; then
            last=$(ls -1 results/rgp_ns/${TODAY}_${BASE}_grid_batch*.metrics.json | sed -E 's/.*_batch([0-9]+)\.metrics\.json/\1/' | sort -n | tail -1)
            NEXT=$(( last + 1 ))
          else
            NEXT=1
          fi

          # Pick the best shard (simple ladder+dominance heuristic)
          SEL=$(python - <<'PY'
import json,glob,os,sys
stage=os.environ.get("STAGE","")
best=None; best_score=-1.0; pick=None
for fp in glob.glob(os.path.join(stage,"*.json")):
    try:
        with open(fp,"r",encoding="utf-8") as f:
            m=json.load(f)
    except Exception:
        continue
    peaks=m.get("peaks") or []
    ladder=len(peaks)
    main=peaks[0][1] if peaks else 0.0
    dom=1.0
    if len(peaks)>=2 and peaks[1][1]>0:
        dom=float(peaks[0][1])/float(peaks[1][1])
    score=(2.0 if ladder>=3 else 0.0) + (1.0 if ladder>=2 else 0.0) + 0.25*dom + (0.01 if main>0 else 0.0)
    if score>best_score:
        best_score=score; best=m; pick=fp
if not best:
    print("")
    sys.exit(0)
print(json.dumps({"file":pick,"metrics":best,"score":best_score}))
PY
)
          echo "selection=${SEL}" >> "$GITHUB_OUTPUT"
          echo "batch=${NEXT}"    >> "$GITHUB_OUTPUT"

      - name: Write canonical metrics + emit pulse
        if: ${{ steps.select.outputs.selection != '' }}
        shell: bash
        env:
          TITLE:   ${{ github.event.inputs.title }}
          TAGS:    ${{ github.event.inputs.tags }}
          BASE:    ${{ needs.plan.outputs.base }}
          TODAY:   ${{ needs.plan.outputs.today }}
          BATCH:   ${{ steps.select.outputs.batch }}
        run: |
          set -euo pipefail
          # Extract the selected shard metrics filepath
          SEL_FILE=$(python -c 'import json,sys; print(json.loads(sys.argv[1])["file"])' '${{ steps.select.outputs.selection }}')

          # Move to canonical, dated filename
          CANON="results/rgp_ns/${TODAY}_${BASE}_grid_batch${BATCH}.metrics.json"
          cp "$SEL_FILE" "$CANON"

          # Pulse slug keeps _batchN
          PULSE_SLUG="${BASE}_grid_batch${BATCH}"

          # Emit pulse (make_pulse reads metrics & adds hint)
          python tools/agent_rhythm/make_pulse.py \
            --metrics "$CANON" \
            --title   "$TITLE" \
            --dataset "$PULSE_SLUG" \
            --tags    "$TAGS" \
            --outdir  "pulse/auto"

      - name: Commit consolidated results + pulse
        run: |
          set -euo pipefail
          git config user.name  "phi-mesh-bot"
          git config user.email "actions@users.noreply.github.com"
          git add results/rgp_ns/*.json pulse/auto/*.yml
          git add maps/* || true
          git commit -m "auto: RGP–NS grid (${{ needs.plan.outputs.today }} ${{ needs.plan.outputs.base }}) consolidated results + pulse" || echo "Nothing to commit"
          git push
